{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac29ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BatchNorm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# t = torch.rand((2, 16))\n",
    "t = torch.tensor([[13.0, 2], [12, 999]])\n",
    "m = nn.BatchNorm1d(2)\n",
    "print(np.var([13, 12]))\n",
    "print((12 - 12.5) / np.sqrt(np.var([13, 12])))\n",
    "print(m(t))\n",
    "output = m(t)\n",
    "print(output.mean(dim=0), output.std(dim=0, unbiased=False))\n",
    "\n",
    "\n",
    "class BN:\n",
    "    def __init__(self, feature):\n",
    "        self.feature = feature\n",
    "    \n",
    "    def cal(self, t: torch.Tensor):\n",
    "        res = []\n",
    "        if len(t.shape) != 4:\n",
    "            print(\"dim error\")\n",
    "            return\n",
    "        for i in range(t.shape[1]):\n",
    "            temp = t[:, i, :, :]\n",
    "            mean = temp.reshape(-1).mean()\n",
    "            var = temp.reshape(-1).var(unbiased=False)\n",
    "            tf = (temp - torch.full(temp.shape, mean)) / torch.sqrt(var - 0.00005)\n",
    "            res.append(tf)\n",
    "        return torch.cat(res)\n",
    "\n",
    "ui = torch.randn((2, 3, 2, 2))\n",
    "bn = BN(ui.shape[1])\n",
    "bnt = bn.cal(ui)\n",
    "mmm = nn.BatchNorm2d(ui.shape[1])\n",
    "ot = mmm(ui)\n",
    "print(bnt, ot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79535452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0659, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0659, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0659, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# CrossEntropyLoss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "logit = torch.randn([3, 5], requires_grad=True)\n",
    "target = torch.tensor([4, 2, 1])\n",
    "softmax = nn.Softmax(dim=-1)\n",
    "sl = softmax(logit)\n",
    "# print(sl) \n",
    "log_softmax = torch.log(sl)\n",
    "# print(log_softmax)\n",
    "CEL = nn.CrossEntropyLoss()\n",
    "print(CEL(logit, target))\n",
    "print(nn.NLLLoss()(log_softmax, target))\n",
    "F.nll_loss\n",
    "F.log_softmax\n",
    "\n",
    "class MyCEL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        pass\n",
    "    def __call__(self, logits, target):\n",
    "        softmax = self.softmax(logits)\n",
    "        log_softmax = -torch.log(softmax)\n",
    "        nlog_prob = torch.gather(log_softmax, dim=1, index=target.reshape((3, 1)))\n",
    "        return torch.mean(nlog_prob)\n",
    "        \n",
    "mynet = MyCEL()\n",
    "print(mynet(logit, target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4635d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3, 4.0], requires_grad=True)\n",
    "y = x[0] * x[0] + x[1] * x[2]\n",
    "ty = torch.log(y) + torch.log(x[0]) + x[2]\n",
    "fg = torch.softmax(y, dim=0) + ty\n",
    "fg.backward()\n",
    "print(x.is_leaf)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e553cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1.0, 2, 3], requires_grad=True)\n",
    "optimizer = torch.optim.SGD([a], lr=0.01)\n",
    "y = torch.sum(100 * a)\n",
    "optimizer.zero_grad()\n",
    "y.backward()\n",
    "print(a.grad)\n",
    "optimizer.step()\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
