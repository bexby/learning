{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(2, 3)\n",
    "mask = torch.tensor([True, False, True])  # shape (3,)\n",
    "x.masked_fill(mask, 0)  # ❌ 错，因为 (3,) 无法广播到 (2, 3)\n",
    "\n",
    "a = torch.rand((3, 5))\n",
    "print(a)\n",
    "print(a.unsqueeze(1))\n",
    "print(a.unsqueeze(1).unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "N, num_head, q_seq_len, k_seq_len = 1, 2, 5, 5\n",
    "mul_res = torch.tensor([[\n",
    "[\n",
    "    [1.2, 0.3, 0.4, 0.2, 0.1],  # token 0\n",
    "    [0.3, 1.0, 0.6, 0.5, 0.1],  # token 1\n",
    "    [0.4, 0.6, 1.3, 0.7, 0.2],  # token 2\n",
    "    [0.2, 0.5, 0.7, 1.1, 0.4],  # token 3\n",
    "    [0.1, 0.1, 0.2, 0.4, 1.5]   # token 4 (padding)\n",
    "],\n",
    "[\n",
    "    [0.4, 0.6, 1.3, 0.7, 0.2],  \n",
    "    [0.2, 0.5, 0.7, 1.1, 0.4],  \n",
    "    [0.1, 0.1, 0.2, 0.4, 1.5],\n",
    "    [1.2, 0.3, 0.4, 0.2, 0.1],  \n",
    "    [0.3, 1.0, 0.6, 0.5, 0.1],  \n",
    "]\n",
    "]])\n",
    "# print(mul_res.shape)    # (N, num_head, q_len, k_len)\n",
    "key_padding_mask = torch.tensor([[False, False, False, False, True]])  # 只有最后一个 token 是 padding\n",
    "# print(key_padding_mask)\n",
    "attn_mask = torch.triu(torch.ones((q_seq_len, k_seq_len)), diagonal=1).bool()   # (q_len=5, k_len=5)\n",
    "\n",
    "if key_padding_mask is not None:\n",
    "    key_padding_mask = key_padding_mask.unsqueeze(1).unsqueeze(2)\n",
    "    key_padding_mask = key_padding_mask.expand((N, num_head, q_seq_len, k_seq_len))\n",
    "    mul_res = torch.masked_fill(mul_res, key_padding_mask, -torch.inf)\n",
    "print(mul_res.shape)\n",
    "print(mul_res)\n",
    "if attn_mask is not None:\n",
    "    attn_mask = attn_mask.unsqueeze(0).unsqueeze(0)\n",
    "    attn_mask = attn_mask.expand((N, num_head, q_seq_len, k_seq_len))\n",
    "    mul_res = torch.masked_fill(mul_res, attn_mask, -torch.inf)\n",
    "print(mul_res.shape)\n",
    "print(mul_res)\n",
    "\n",
    "# key_padding_mask = key_padding_mask.unsqueeze(1).unsqueeze(2)\n",
    "# key_padding_mask = key_padding_mask.expand((1, num_head, 5, 5))\n",
    "# print(key_padding_mask)\n",
    "# print(torch.softmax(torch.tensor([float(\"inf\"), float(\"inf\")]), dim=0))\n",
    "# attn_output_weights = attn_output_weights.masked_fill(, float('-inf'))\n",
    "# print(attn_output_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from transformers import AutoModel\n",
    "from transformers import BertModel\n",
    "\n",
    "ckp = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "bert = AutoModel.from_pretrained(ckp)\n",
    "print(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8358)\n",
      "tensor(0.8358)\n",
      "tensor(0.8265)\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "inputs = torch.randn((2, 3))\n",
    "inputs = torch.softmax(inputs, dim=0)\n",
    "labels = torch.tensor([0, 2])\n",
    "print(nn.CrossEntropyLoss()(inputs, labels))\n",
    "print(F.cross_entropy(inputs, labels))\n",
    "print(F.cross_entropy(inputs[0], labels[0]))\n",
    "\n",
    "print(inputs[:, 0:2].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# t = torch.arange(24).view(2, 3, 4)\n",
    "# print(t)\n",
    "# t = t.view(2, 4, 3)\n",
    "# print(t)\n",
    "\n",
    "\n",
    "a = torch.arange(12)\n",
    "print(torch.stack([a] * 3, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "selected index k out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res_values, res_indices\n\u001b[0;32m     22\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m---> 23\u001b[0m v, i \u001b[38;5;241m=\u001b[39m \u001b[43mtop_p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m, in \u001b[0;36mtop_p\u001b[1;34m(data, p)\u001b[0m\n\u001b[0;32m      4\u001b[0m max_k \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      5\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[1;32m----> 6\u001b[0m top_k, indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m# top_k has been sorted by descending order\u001b[39;00m\n\u001b[0;32m      7\u001b[0m cumsum \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcumsum(top_k, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(cumsum[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m p)\u001b[38;5;241m.\u001b[39mitem():     \u001b[38;5;66;03m# if k is not large enough to cover cumulated probability p \u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: selected index k out of range"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def top_p(data: torch.Tensor, p):\n",
    "    max_k = data.shape[-1]\n",
    "    k = 2000\n",
    "    top_k, indices = torch.topk(data, k)    # top_k has been sorted by descending order\n",
    "    cumsum = torch.cumsum(top_k, dim=-1)\n",
    "    if not torch.all(cumsum[:, -1] > p).item():     # if k is not large enough to cover cumulated probability p \n",
    "        top_k, indices = torch.topk(data, max_k)\n",
    "        cumsum = torch.cumsum(top_k, dim=-1)\n",
    "    sorted_cum_topk, sorted_cum_indices = torch.sort(cumsum, dim=-1, descending=True) \n",
    "    targets = torch.searchsorted(sorted_cum_topk, p)\n",
    "    bs, max_len = sorted_cum_topk.shape\n",
    "    positions = torch.arange(max_len).unsqueeze(0).expand(bs, -1)\n",
    "    top_k = top_k.masked_fill(positions > targets, 0)\n",
    "    samples_idx = torch.multinomial(top_k, 1)\n",
    "    res_indices = torch.gather(indices, -1, samples_idx)\n",
    "    res_values = torch.gather(data, -1, res_indices)\n",
    "    return res_values, res_indices\n",
    "\n",
    "\n",
    "t = torch.randn((2, 10))\n",
    "v, i = top_p(t, 0.6)\n",
    "# print(t)\n",
    "# print(v)\n",
    "# print(i)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
