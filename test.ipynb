{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3969, 0.2800, 0.8349, 0.2901, 0.6935],\n",
      "        [0.8142, 0.6477, 0.4673, 0.2253, 0.5960],\n",
      "        [0.6400, 0.8461, 0.3737, 0.8131, 0.2501]])\n",
      "tensor([[[0.3969, 0.2800, 0.8349, 0.2901, 0.6935]],\n",
      "\n",
      "        [[0.8142, 0.6477, 0.4673, 0.2253, 0.5960]],\n",
      "\n",
      "        [[0.6400, 0.8461, 0.3737, 0.8131, 0.2501]]])\n",
      "tensor([[[[0.3969],\n",
      "          [0.2800],\n",
      "          [0.8349],\n",
      "          [0.2901],\n",
      "          [0.6935]]],\n",
      "\n",
      "\n",
      "        [[[0.8142],\n",
      "          [0.6477],\n",
      "          [0.4673],\n",
      "          [0.2253],\n",
      "          [0.5960]]],\n",
      "\n",
      "\n",
      "        [[[0.6400],\n",
      "          [0.8461],\n",
      "          [0.3737],\n",
      "          [0.8131],\n",
      "          [0.2501]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(2, 3)\n",
    "mask = torch.tensor([True, False, True])  # shape (3,)\n",
    "x.masked_fill(mask, 0)  # ❌ 错，因为 (3,) 无法广播到 (2, 3)\n",
    "\n",
    "a = torch.rand((3, 5))\n",
    "print(a)\n",
    "print(a.unsqueeze(1))\n",
    "print(a.unsqueeze(1).unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 5, 5])\n",
      "tensor([[[[1.2000, 0.3000, 0.4000, 0.2000,   -inf],\n",
      "          [0.3000, 1.0000, 0.6000, 0.5000,   -inf],\n",
      "          [0.4000, 0.6000, 1.3000, 0.7000,   -inf],\n",
      "          [0.2000, 0.5000, 0.7000, 1.1000,   -inf],\n",
      "          [0.1000, 0.1000, 0.2000, 0.4000,   -inf]],\n",
      "\n",
      "         [[0.4000, 0.6000, 1.3000, 0.7000,   -inf],\n",
      "          [0.2000, 0.5000, 0.7000, 1.1000,   -inf],\n",
      "          [0.1000, 0.1000, 0.2000, 0.4000,   -inf],\n",
      "          [1.2000, 0.3000, 0.4000, 0.2000,   -inf],\n",
      "          [0.3000, 1.0000, 0.6000, 0.5000,   -inf]]]])\n",
      "torch.Size([1, 2, 5, 5])\n",
      "tensor([[[[1.2000,   -inf,   -inf,   -inf,   -inf],\n",
      "          [0.3000, 1.0000,   -inf,   -inf,   -inf],\n",
      "          [0.4000, 0.6000, 1.3000,   -inf,   -inf],\n",
      "          [0.2000, 0.5000, 0.7000, 1.1000,   -inf],\n",
      "          [0.1000, 0.1000, 0.2000, 0.4000,   -inf]],\n",
      "\n",
      "         [[0.4000,   -inf,   -inf,   -inf,   -inf],\n",
      "          [0.2000, 0.5000,   -inf,   -inf,   -inf],\n",
      "          [0.1000, 0.1000, 0.2000,   -inf,   -inf],\n",
      "          [1.2000, 0.3000, 0.4000, 0.2000,   -inf],\n",
      "          [0.3000, 1.0000, 0.6000, 0.5000,   -inf]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "N, num_head, q_seq_len, k_seq_len = 1, 2, 5, 5\n",
    "mul_res = torch.tensor([[\n",
    "[\n",
    "    [1.2, 0.3, 0.4, 0.2, 0.1],  # token 0\n",
    "    [0.3, 1.0, 0.6, 0.5, 0.1],  # token 1\n",
    "    [0.4, 0.6, 1.3, 0.7, 0.2],  # token 2\n",
    "    [0.2, 0.5, 0.7, 1.1, 0.4],  # token 3\n",
    "    [0.1, 0.1, 0.2, 0.4, 1.5]   # token 4 (padding)\n",
    "],\n",
    "[\n",
    "    [0.4, 0.6, 1.3, 0.7, 0.2],  \n",
    "    [0.2, 0.5, 0.7, 1.1, 0.4],  \n",
    "    [0.1, 0.1, 0.2, 0.4, 1.5],\n",
    "    [1.2, 0.3, 0.4, 0.2, 0.1],  \n",
    "    [0.3, 1.0, 0.6, 0.5, 0.1],  \n",
    "]\n",
    "]])\n",
    "# print(mul_res.shape)    # (N, num_head, q_len, k_len)\n",
    "key_padding_mask = torch.tensor([[False, False, False, False, True]])  # 只有最后一个 token 是 padding\n",
    "# print(key_padding_mask)\n",
    "attn_mask = torch.triu(torch.ones((q_seq_len, k_seq_len)), diagonal=1).bool()   # (q_len=5, k_len=5)\n",
    "\n",
    "if key_padding_mask is not None:\n",
    "    key_padding_mask = key_padding_mask.unsqueeze(1).unsqueeze(2)\n",
    "    key_padding_mask = key_padding_mask.expand((N, num_head, q_seq_len, k_seq_len))\n",
    "    mul_res = torch.masked_fill(mul_res, key_padding_mask, -torch.inf)\n",
    "print(mul_res.shape)\n",
    "print(mul_res)\n",
    "if attn_mask is not None:\n",
    "    attn_mask = attn_mask.unsqueeze(0).unsqueeze(0)\n",
    "    attn_mask = attn_mask.expand((N, num_head, q_seq_len, k_seq_len))\n",
    "    mul_res = torch.masked_fill(mul_res, attn_mask, -torch.inf)\n",
    "print(mul_res.shape)\n",
    "print(mul_res)\n",
    "\n",
    "# key_padding_mask = key_padding_mask.unsqueeze(1).unsqueeze(2)\n",
    "# key_padding_mask = key_padding_mask.expand((1, num_head, 5, 5))\n",
    "# print(key_padding_mask)\n",
    "# print(torch.softmax(torch.tensor([float(\"inf\"), float(\"inf\")]), dim=0))\n",
    "# attn_output_weights = attn_output_weights.masked_fill(, float('-inf'))\n",
    "# print(attn_output_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSdpaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from transformers import AutoModel\n",
    "\n",
    "ckp = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "bert = AutoModel.from_pretrained(ckp)\n",
    "print(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3060,  1.7448,  0.5608, -1.4517,  0.3484],\n",
      "         [-1.2369, -0.2216,  0.1535, -0.0511,  0.7589]],\n",
      "\n",
      "        [[-0.3060,  1.7448,  0.5608, -1.4517,  0.3484],\n",
      "         [-0.2811, -1.6255, -1.2007, -0.1995,  0.1456]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "emb = nn.Embedding(10, 5)\n",
    "\n",
    "print(emb(torch.tensor([[1, 3], [1, 2]])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
