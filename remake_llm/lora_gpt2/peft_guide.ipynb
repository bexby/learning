{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEFT库使用\n",
    "## 1.PeftConfig\n",
    "- 每一个peft方法都对应一个config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftConfig, LoraConfig\n",
    "\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\", #type of task to train model on\n",
    "    inference_mode=False, \n",
    "    r=8, \n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.PeftModel\n",
    "- 可以在transformers中加载任何模型后, 使用`get_peft_model`将其转化为`PeftModel`\n",
    "- 调用`get_peft_model`后, the base model will be modified in-place.\n",
    "- 或者使用`Model.add_adapter`添加(多个adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, PeftModel\n",
    "from transformers import AutoModel\n",
    "\n",
    "ckp = \"\"\n",
    "model = AutoModel.from_pretrained(ckp)\n",
    "\n",
    "peft_model = get_peft_model(\n",
    "    model=model, \n",
    "    peft_config=lora_config\n",
    ")\n",
    "# model.add_adapter(lora_config, adapter_name=\"aaa\")\n",
    "# model.set_adapter(\"aaa\")\n",
    "peft_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.训练\n",
    "- 得到`PeftModel`后, 使用`Trainer`或者自己写的Pytorch训练脚本即可训练\n",
    "- 保存只保存额外的peft权重, 例如用lora训练后只保存`adapter_config.json`和`adapter_model.safetensors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "train_arg = TrainingArguments()\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=train_arg\n",
    ")\n",
    "trainer.train()\n",
    "peft_model.save_pretrained(\"output_dir\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.推理\n",
    "- 加载一个peft后的模型, 应注意文件是否有`adapter_config.json`\n",
    "- By default, the PeftModel is set for inference, but if you’d like to train the adapter some more you can set is_trainable=True\n",
    "- The PeftModel.from_pretrained() method is the most flexible way to load a PeftModel because it doesn’t matter what model framework was used (Transformers, timm, a generic PyTorch model). Other classes, like AutoPeftModel, are just a convenient wrapper around the base PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "save_ckp = \"\"\n",
    "inference_model = AutoPeftModelForCausalLM.from_pretrained(save_ckp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
